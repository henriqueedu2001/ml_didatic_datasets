# from mldd import ML_TASKS
from regression_gen import generate_linear_dataset
import numpy as np

MAX_FEATURE_VALUE = 100
MAX_WEIGHT_VALUE = 30

DATASET_GENERATORS = {
    'linear_regression': generate_linear_dataset
}

class DatasetGenerator:
    def generate(params: dict) -> np.array:
        print(params)
        dimensions = params['dimensions']
        weights = DatasetGenerator.random_weights(dimensions + 1)
        size = params['size']
        
        dataset = np.zeros((size, dimensions + 1))
        
        # generating x
        for column_index in range(dimensions):
            new_column = DistributionGenerator.generate_uniform_dist(
                size,
                -MAX_FEATURE_VALUE,
                MAX_FEATURE_VALUE
            )
            dataset[:, column_index] = new_column
        
        # generating y
        for line_index in range(size):
            x = dataset[line_index, :-1]
            y = weights[0] + DatasetGenerator.weighted_sum(x, weights[1:])
            dataset[line_index, -1] = y
        
        print(dataset)
    
    
    def random_weights(dimensions: int, maximum: float = MAX_WEIGHT_VALUE) -> np.array:
        """Generates a random n-dimentional weight vector w = (w_1, w_2, w_3, ..., w_n), 
        where every w_i is generated by an uniform distribution over the interval 
        [-maximum, maximum)

        Args:
            dimensions (int): dimension of the weight vector w

        Returns:
            np.array: weight vector w (w_1, w_2, w_3, ..., w_n)
        """
        # n random weights in [0, 1)
        weights = np.random.rand(dimensions)
        
        # mapping the n weights in to [-1, 1) 
        weights = 2*(weights - 0.5)
        
        # scaling up to [-max, max)
        scaling_factor = np.random.uniform(-maximum, maximum)
        weights = weights*scaling_factor
    
        return weights
    
    
    def weighted_sum(x: np.array, weigths: np.array):
        return np.dot(x, weigths)


class DistributionGenerator:
    def generate_uniform_dist(dataset_size: int, min_value: float, max_value: float) -> np.array:
        """Gera uma distribuição uniforme no intervalo (a,b)

        Args:
            dataset_size (int): quantidade de pontos do dataset
            min_value (float): valor mínimo da distribuição
            max_value (float): valor máximo da distribuição

        Returns:
            np.array: dataaset com valores distribuídos uniformemente
        """
        # geranção de n=dataset_size valores no intervalo [0,1)
        dataset = np.random.random(dataset_size)
        
        # transformação linear de [0,1) até [a, b)
        dataset = min_value + (max_value - min_value)*dataset
        
        return dataset
    
    
    def generate_normal_dist(dataset_size: int, mean: float, std_dev: float) -> np.array:
        """Gera uma distribuição normal N(mu, sigma)

        Args:
            dataset_size (int): quantidade de pontos do dataset
            mean (float): média
            std_dev (float): desvio padrão da distribuição normal (sigma)

        Returns:
            np.array: dataset com valores distribuídos normalmente
        """
        return np.random.normal(mean, std_dev, dataset_size)
    
    
    def generate_binomial_dist(dataset_size: int, sucess_prob: float, n: int) -> np.array:
        """Gera uma distribuição binomial 

        Args:
            dataset_size (int): quantidade de pontos do dataset
            sucess_prob (float): probabilidade de sucesso
            n (int): parâmetro n da distribuição

        Returns:
            np.array: dataset com os valores distribuídos binomialmente
        """
        return np.random.binomial(n, sucess_prob, dataset_size)